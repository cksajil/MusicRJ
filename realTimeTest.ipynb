{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 256\n",
    "WIDTH = 2\n",
    "CHANNELS = 1\n",
    "RATE = 48000\n",
    "RECORD_SECONDS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creal Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation = 'relu', input_shape= (1, 256)))\n",
    "    model.add(Dense(512, kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "        activation=tf.nn.relu))\n",
    "    model.add(Dense(128, activation = 'sigmoid', \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    model.add(Dense (128, activation = 'relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(Dense (64, activation = 'sigmoid', \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    model.add(Dense(2, kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "        activation=tf.nn.softmax))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model instance and load previously trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f913c5907f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltoDeploy = create_model()\n",
    "checkpoint_path = \"./TrainedModel/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "modeltoDeploy.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set output labels and probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Female', 'Male']\n",
    "probability_model = Sequential([modeltoDeploy, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pyaudio streaming handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=p.get_format_from_width(WIDTH),\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                output=True,\n",
    "                input_device_index=7,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record voice and predict gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted gender of voice:  Male\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "freqData = np.empty((0, CHUNK), int)\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    clear_output(wait=True)\n",
    "    data = stream.read(CHUNK)\n",
    "    data = np.frombuffer(data , np.int16)\n",
    "    data = np.abs(np.fft.fft(data))\n",
    "    row = [list(data)]\n",
    "    try:\n",
    "        predictions = probability_model.predict(row)\n",
    "        index = np.argmax(predictions[0])\n",
    "        print(\"Predicted gender of voice: \",classes[index])\n",
    "    except Exception as e:\n",
    "        raise\n",
    "    else:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close pyaudio stream and instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
